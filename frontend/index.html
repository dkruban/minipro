const express = require('express');
const router = express.Router();

// Direct test endpoint to check available models
router.get('/check-models', async (req, res) => {
  try {
    const apiKey = process.env.GEMINI_API_KEY;
    
    if (!apiKey) {
      return res.status(500).json({ 
        error: 'API key not configured on server'
      });
    }
    
    console.log('Checking available models with API key...');
    
    // Get the list of available models
    const modelsResponse = await fetch(`https://generativelanguage.googleapis.com/v1beta/models?key=${apiKey}`);
    const modelsData = await modelsResponse.json();
    
    if (modelsData.error) {
      console.error('Error getting models:', modelsData.error);
      return res.status(500).json({ 
        error: `Error getting models: ${modelsData.error.message}`
      });
    }
    
    console.log('Available models:', modelsData.models.map(m => m.name));
    
    // Find all models that support generateContent
    const supportedModels = modelsData.models.filter(model => 
      model.supportedGenerationMethods && 
      model.supportedGenerationMethods.includes('generateContent')
    );
    
    console.log('Models that support generateContent:', supportedModels.map(m => m.name));
    
    // Try to find the best model
    let bestModel = null;
    
    // Check for the new model names - prioritize gemini-2.5-flash over gemini-pro-latest
    const preferredModels = [
      'gemini-2.5-flash',
      'gemini-2.5-pro',
      'gemini-2.0-flash',
      'gemini-2.0-pro-exp',
      'gemini-flash-latest',
      'gemini-pro-latest',
      'gemini-1.5-pro',
      'gemini-1.5-flash'
    ];
    
    for (const modelName of preferredModels) {
      const model = supportedModels.find(m => m.name.includes(modelName));
      if (model) {
        bestModel = model.name;
        console.log('Found preferred model:', bestModel);
        break;
      }
    }
    
    // If no preferred model found, use the first available one
    if (!bestModel && supportedModels.length > 0) {
      bestModel = supportedModels[0].name;
      console.log('Using first available model:', bestModel);
    }
    
    if (!bestModel) {
      return res.status(500).json({ 
        error: 'No models found that support generateContent',
        allModels: modelsData.models.map(m => ({
          name: m.name,
          methods: m.supportedGenerationMethods || []
        }))
      });
    }
    
    // Test the selected model
    console.log('Testing model:', bestModel);
    
    const testResponse = await fetch(`https://generativelanguage.googleapis.com/v1beta/${bestModel}:generateContent?key=${apiKey}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [
          {
            parts: [
              {
                text: "Respond with just the word 'working'"
              }
            ]
          }
        ],
        generationConfig: {
          temperature: 0.7,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 2048,
        }
      })
    });
    
    if (!testResponse.ok) {
      const errorData = await testResponse.json();
      console.error('Model test failed:', errorData);
      return res.status(500).json({ 
        error: `Model test failed: ${errorData.error?.message || 'Unknown error'}`,
        model: bestModel
      });
    }
    
    const testData = await testResponse.json();
    
    if (testData.candidates && testData.candidates.length > 0 && 
        testData.candidates[0].content && testData.candidates[0].content.parts && 
        testData.candidates[0].content.parts.length > 0) {
      return res.json({ 
        message: 'API key is working correctly',
        model: bestModel,
        response: testData.candidates[0].content.parts[0].text,
        allModels: modelsData.models.map(m => ({
          name: m.name,
          methods: m.supportedGenerationMethods || []
        }))
      });
    } else {
      return res.status(500).json({ 
        error: 'Model test failed - no valid response',
        model: bestModel,
        response: testData
      });
    }
  } catch (error) {
    console.error('Error checking models:', error);
    return res.status(500).json({ 
      error: `Error checking models: ${error.message}`
    });
  }
});

// Gemini API endpoint with correct model detection and better error handling
router.post('/gemini', async (req, res) => {
  try {
    const { prompt } = req.body;
    const apiKey = process.env.GEMINI_API_KEY;
    
    if (!apiKey) {
      console.error('Gemini API key not configured');
      return res.status(500).json({ 
        error: 'API key not configured on server',
        details: 'Please add GEMINI_API_KEY to your environment variables'
      });
    }
    
    if (!prompt || prompt.trim() === '') {
      return res.status(400).json({ 
        error: 'No prompt provided',
        details: 'Please include a prompt in your request'
      });
    }
    
    console.log('Sending prompt to Gemini:', prompt.substring(0, 100) + '...');
    
    // Get the list of available models
    const modelsResponse = await fetch(`https://generativelanguage.googleapis.com/v1beta/models?key=${apiKey}`);
    const modelsData = await modelsResponse.json();
    
    if (modelsData.error) {
      console.error('Error getting models:', modelsData.error);
      return res.status(500).json({ 
        error: `Error getting models: ${modelsData.error.message}`
      });
    }
    
    // Find all models that support generateContent
    const supportedModels = modelsData.models.filter(model => 
      model.supportedGenerationMethods && 
      model.supportedGenerationMethods.includes('generateContent')
    );
    
    // Try to find the best model
    let bestModel = null;
    
    // Check for the new model names - prioritize gemini-2.5-flash over gemini-pro-latest
    const preferredModels = [
      'gemini-2.5-flash',
      'gemini-2.5-pro',
      'gemini-2.0-flash',
      'gemini-2.0-pro-exp',
      'gemini-flash-latest',
      'gemini-pro-latest',
      'gemini-1.5-pro',
      'gemini-1.5-flash'
    ];
    
    for (const modelName of preferredModels) {
      const model = supportedModels.find(m => m.name.includes(modelName));
      if (model) {
        bestModel = model.name;
        break;
      }
    }
    
    // If no preferred model found, use the first available one
    if (!bestModel && supportedModels.length > 0) {
      bestModel = supportedModels[0].name;
    }
    
    if (!bestModel) {
      return res.status(500).json({ 
        error: 'No models found that support generateContent',
        availableModels: modelsData.models.map(m => ({
          name: m.name,
          methods: m.supportedGenerationMethods || []
        }))
      });
    }
    
    console.log('Using model:', bestModel);
    
    // Use the found model with increased maxOutputTokens
    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/${bestModel}:generateContent?key=${apiKey}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [
          {
            parts: [
              {
                text: prompt
              }
            ]
          }
        ],
        generationConfig: {
          temperature: 0.7,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 2048,
        }
      })
    });
    
    if (!response.ok) {
      const errorData = await response.json();
      console.error('Gemini API error:', errorData);
      
      // Handle specific error cases
      if (response.status === 400) {
        return res.status(400).json({ 
          error: 'Bad request to Gemini API',
          details: errorData.error?.message || 'Invalid request format'
        });
      } else if (response.status === 403) {
        return res.status(403).json({ 
          error: 'API key invalid or quota exceeded',
          details: 'Please check your API key and usage limits'
        });
      } else if (response.status === 429) {
        return res.status(429).json({ 
          error: 'Rate limit exceeded',
          details: 'Too many requests. Please try again later'
        });
      } else {
        return res.status(response.status).json({ 
          error: `API Error: ${errorData.error?.message || 'Unknown error'}`,
          status: response.status
        });
      }
    }
    
    const data = await response.json();
    console.log('Gemini response received');
    console.log('Response structure:', JSON.stringify(data, null, 2));
    
    // Better error handling for the response structure
    if (!data) {
      console.error('No data in response');
      return res.status(500).json({ 
        error: 'No data in response',
        details: 'Gemini API returned an empty response'
      });
    }
    
    if (!data.candidates) {
      console.error('No candidates in response');
      return res.status(500).json({ 
        error: 'No candidates in response',
        details: 'Gemini API returned a response without candidates',
        response: data
      });
    }
    
    if (!Array.isArray(data.candidates) || data.candidates.length === 0) {
      console.error('Candidates is not an array or is empty');
      return res.status(500).json({ 
        error: 'Candidates is not an array or is empty',
        details: 'Gemini API returned invalid candidates',
        candidates: data.candidates
      });
    }
    
    if (!data.candidates[0]) {
      console.error('First candidate is undefined');
      return res.status(500).json({ 
        error: 'First candidate is undefined',
        details: 'Gemini API returned an undefined candidate',
        candidates: data.candidates
      });
    }
    
    if (!data.candidates[0].content) {
      console.error('No content in first candidate');
      return res.status(500).json({ 
        error: 'No content in first candidate',
        details: 'Gemini API returned a candidate without content',
        candidate: data.candidates[0]
      });
    }
    
    // Check if finishReason is MAX_TOKENS and try again with higher limit
    if (data.candidates[0].finishReason === 'MAX_TOKENS') {
      console.log('Response was cut off due to MAX_TOKENS, trying again with higher limit...');
      
      // Try again with even higher token limit
      const retryResponse = await fetch(`https://generativelanguage.googleapis.com/v1beta/${bestModel}:generateContent?key=${apiKey}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          contents: [
            {
              parts: [
                {
                  text: prompt
                }
              ]
            }
          ],
          generationConfig: {
            temperature: 0.7,
            topK: 40,
            topP: 0.95,
            maxOutputTokens: 4096,
          }
        })
      });
      
      if (retryResponse.ok) {
        const retryData = await retryResponse.json();
        console.log('Retry response received');
        
        // Check if the retry response has valid content
        if (retryData.candidates && 
            retryData.candidates.length > 0 && 
            retryData.candidates[0].content && 
            retryData.candidates[0].content.parts && 
            retryData.candidates[0].content.parts.length > 0) {
          const text = retryData.candidates[0].content.parts[0].text;
          return res.json({ response: text, model: bestModel });
        }
      }
    }
    
    // If we get here, either the retry failed or we didn't need to retry
    if (!data.candidates[0].content.parts) {
      console.error('No parts in content');
      
      // Try a different model if the current one doesn't work
      if (bestModel.includes('gemini-pro-latest')) {
        console.log('Trying a different model...');
        const flashModel = supportedModels.find(m => m.name.includes('gemini-2.5-flash'));
        
        if (flashModel) {
          console.log('Retrying with model:', flashModel.name);
          
          const retryResponse = await fetch(`https://generativelanguage.googleapis.com/v1beta/${flashModel.name}:generateContent?key=${apiKey}`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              contents: [
                {
                  parts: [
                    {
                      text: prompt
                    }
                  ]
                }
              ],
              generationConfig: {
                temperature: 0.7,
                topK: 40,
                topP: 0.95,
                maxOutputTokens: 2048,
              }
            })
          });
          
          if (retryResponse.ok) {
            const retryData = await retryResponse.json();
            
            if (retryData.candidates && 
                retryData.candidates.length > 0 && 
                retryData.candidates[0].content && 
                retryData.candidates[0].content.parts && 
                retryData.candidates[0].content.parts.length > 0) {
              const text = retryData.candidates[0].content.parts[0].text;
              return res.json({ response: text, model: flashModel.name });
            }
          }
        }
      }
      
      return res.status(500).json({ 
        error: 'No parts in content',
        details: 'Gemini API returned content without parts',
        content: data.candidates[0].content
      });
    }
    
    if (!Array.isArray(data.candidates[0].content.parts) || data.candidates[0].content.parts.length === 0) {
      console.error('Parts is not an array or is empty');
      return res.status(500).json({ 
        error: 'Parts is not an array or is empty',
        details: 'Gemini API returned invalid parts',
        parts: data.candidates[0].content.parts
      });
    }
    
    if (!data.candidates[0].content.parts[0]) {
      console.error('First part is undefined');
      return res.status(500).json({ 
        error: 'First part is undefined',
        details: 'Gemini API returned an undefined part',
        parts: data.candidates[0].content.parts
      });
    }
    
    if (!data.candidates[0].content.parts[0].text) {
      console.error('No text in first part');
      return res.status(500).json({ 
        error: 'No text in first part',
        details: 'Gemini API returned a part without text',
        part: data.candidates[0].content.parts[0]
      });
    }
    
    const text = data.candidates[0].content.parts[0].text;
    return res.json({ response: text, model: bestModel });
  } catch (error) {
    console.error('Error calling Gemini API:', error);
    return res.status(500).json({ 
      error: 'Failed to generate response',
      details: error.message
    });
  }
});

// Test endpoint to verify API key (updated to use the new check-models endpoint)
router.get('/test-key', async (req, res) => {
  try {
    // Redirect to the check-models endpoint
    const checkResponse = await fetch(`${req.protocol}://${req.get('host')}/api/check-models`);
    const data = await checkResponse.json();
    
    if (checkResponse.ok) {
      return res.json({
        message: 'API key is working correctly',
        hasKey: true,
        model: data.model,
        response: data.response
      });
    } else {
      return res.status(checkResponse.status).json({
        error: data.error,
        hasKey: false
      });
    }
  } catch (error) {
    console.error('Error testing API key:', error);
    return res.status(500).json({ 
      error: `Error testing API key: ${error.message}`,
      hasKey: !!process.env.GEMINI_API_KEY
    });
  }
});

// New endpoint to get available voices for text-to-speech
router.get('/voices', (req, res) => {
  try {
    // This is a simple endpoint that returns common voice options
    // In a real implementation, you might want to use a text-to-speech service
    const voices = [
      { name: 'default', description: 'Default system voice' },
      { name: 'female', description: 'Female voice' },
      { name: 'male', description: 'Male voice' }
    ];
    
    return res.json({ voices });
  } catch (error) {
    console.error('Error getting voices:', error);
    return res.status(500).json({ 
      error: 'Failed to get voices',
      details: error.message
    });
  }
});

// New endpoint to convert text to speech (server-side fallback)
router.post('/tts', async (req, res) => {
  try {
    const { text, voice = 'default' } = req.body;
    
    if (!text || text.trim() === '') {
      return res.status(400).json({ 
        error: 'No text provided',
        details: 'Please include text in your request'
      });
    }
    
    // In a real implementation, you would use a text-to-speech service here
    // For now, we'll just return the text as is
    // The client-side will handle the actual text-to-speech
    
    return res.json({ 
      message: 'Text received for speech synthesis',
      text: text,
      voice: voice
    });
  } catch (error) {
    console.error('Error in text-to-speech:', error);
    return res.status(500).json({ 
      error: 'Failed to process text for speech',
      details: error.message
    });
  }
});

module.exports = router;
